<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Agent - All-in-One</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap');
        body {
            font-family: 'Poppins', sans-serif;
            background: linear-gradient(135deg, #fce38a 0%, #fc8a8a 100%);
        }
        .container-card {
            background-color: #ffffff;
            backdrop-filter: blur(10px);
            background-color: rgba(255, 255, 255, 0.9);
            border: 1px solid rgba(255, 255, 255, 0.5);
            box-shadow: 0 10px 25px rgba(0,0,0,0.15);
        }
        .section-card {
            background: rgba(255, 255, 255, 0.7);
            border: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: inset 0 2px 4px rgba(0,0,0,0.05);
        }
        .btn {
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .btn:hover {
            transform: translateY(-2px) scale(1.05);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        .animate-pulse-on-record {
            animation: pulse 1s infinite;
        }
    </style>
</head>
<body class="flex items-center justify-center min-h-screen p-4">

    <div class="container-card max-w-4xl w-full mx-auto p-8 rounded-3xl shadow-2xl space-y-8">

        <!-- Header for the page -->
        <header class="text-center">
            <h1 class="text-5xl font-extrabold text-gray-800 flex items-center justify-center">
                <span class="mr-3">AI Voice Agent</span> üéôÔ∏è
            </h1>
            <p class="mt-2 text-xl text-gray-600">Echo Bot V2 with Full Pipeline</p>
        </header>

        <!-- Echo Bot Section -->
        <section class="section-card p-6 rounded-2xl border border-gray-200">
            <h1 class="text-3xl font-bold text-gray-700 mb-4 flex items-center">
                <span class="mr-2">Full Pipeline</span> ü§ñ
            </h1>
            <div class="mt-4 space-y-6 text-center">
                <p id="status-message" class="text-gray-600 text-lg transition-all duration-300">Press 'Start Recording' to begin.</p>
                <div class="flex justify-center space-x-6">
                    <button id="startButton" class="btn px-8 py-4 bg-green-500 text-white font-bold rounded-full shadow-lg hover:bg-green-600">
                        üî¥ Start Recording
                    </button>
                    <button id="stopButton" class="btn px-8 py-4 bg-red-500 text-white font-bold rounded-full shadow-lg hover:bg-red-600" disabled>
                        ‚èπÔ∏è Stop Recording
                    </button>
                </div>
                <audio id="audioPlayback" class="w-full mt-6 rounded-lg shadow-inner" controls></audio>
            </div>
        </section>
    </div>

    <script>
        // API Configuration
        // üö® IMPORTANT: Replace these placeholders with your actual API keys.
        const GEMINI_API_KEY = "AIzaSyDbfrWHOC0aNXbG3fAwU_kPYxDW67LxLEw";
        const ASSEMBLYAI_API_KEY = "661f2c6b775c428e8f9647c97314d502";
        const GEMINI_LLM_MODEL = 'gemini-1.5-flash-latest';
        const GEMINI_TTS_MODEL = 'gemini-2.5-flash-preview-tts';
        const ASSEMBLYAI_API_URL = 'https://api.assemblyai.com/v2/upload';
        const GEMINI_LLM_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_LLM_MODEL}:generateContent?key=${GEMINI_API_KEY}`;
        const GEMINI_TTS_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_TTS_MODEL}:generateContent?key=${GEMINI_API_KEY}`;
        
        // DOM Elements
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const audioPlayback = document.getElementById('audioPlayback');
        const statusMessage = document.getElementById('status-message');

        // Media Recorder State
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        // --- API Key Validation and Initial Setup ---
        window.onload = function() {
            if (GEMINI_API_KEY === "INSERT_YOUR_GEMINI_API_KEY_HERE" || ASSEMBLYAI_API_KEY === "INSERT_YOUR_ASSEMBLYAI_API_KEY_HERE") {
                updateStatus('üö® Please set your API keys in the code.', 'text-red-500 font-bold');
                startButton.disabled = true;
            } else {
                startButton.addEventListener('click', startRecording);
                stopButton.addEventListener('click', stopRecording);
            }
        };

        // Utility Functions
        function updateStatus(message, color = 'text-gray-600') {
            statusMessage.textContent = message;
            statusMessage.className = `text-lg transition-all duration-300 ${color}`;
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm; codecs=opus' });
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    handleAudioData();
                };

                mediaRecorder.start();
                isRecording = true;
                startButton.disabled = true;
                stopButton.disabled = false;
                updateStatus('Recording...', 'text-red-500');
                statusMessage.classList.add('animate-pulse-on-record');
            } catch (error) {
                console.error('Error accessing microphone:', error);
                updateStatus('Error accessing microphone. Please allow access.', 'text-red-500');
            }
        }

        function stopRecording() {
            if (isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                startButton.disabled = false;
                stopButton.disabled = true;
                updateStatus('Processing...', 'text-blue-500');
                statusMessage.classList.remove('animate-pulse-on-record');
            }
        }

        // Main Audio Handling Pipeline
        async function handleAudioData() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });

            try {
                // Step 1: Transcribe using AssemblyAI
                updateStatus('Uploading audio for transcription...', 'text-blue-500');
                const transcriptionUrl = await uploadAudioToAssemblyAI(audioBlob);

                updateStatus('Transcribing audio...', 'text-blue-500');
                const transcribedText = await getTranscriptionResult(transcriptionUrl);

                if (!transcribedText) {
                    updateStatus('Transcription was empty. Please try again.', 'text-red-500');
                    return;
                }
                updateStatus(`Transcription: "${transcribedText}"`);
                
                // Step 2: Generate response with Gemini LLM
                updateStatus('Generating response with Gemini...', 'text-blue-500');
                const llmResponseText = await generateGeminiText(transcribedText);
                if (!llmResponseText) {
                    updateStatus('Gemini LLM did not return a response.', 'text-red-500');
                    return;
                }
                
                // Step 3: Generate audio from the response with Gemini TTS
                updateStatus('Generating audio with Gemini TTS...', 'text-blue-500');
                const audioBlobFromTTS = await generateGeminiAudio(llmResponseText);

                // Step 4: Play the final audio response
                audioPlayback.src = URL.createObjectURL(audioBlobFromTTS);
                audioPlayback.play();
                updateStatus('Audio response ready. Playing now...', 'text-green-600');

            } catch (error) {
                console.error('Pipeline error:', error);
                updateStatus(`Error: ${error.message}`, 'text-red-500');
            }
        }

        // --- AssemblyAI Functions ---
        async function uploadAudioToAssemblyAI(audioBlob) {
            const response = await fetch(ASSEMBLYAI_API_URL, {
                method: 'POST',
                headers: {
                    'Authorization': ASSEMBLYAI_API_KEY,
                    'Content-Type': 'application/json'
                },
                body: audioBlob
            });

            if (response.status === 401) {
                throw new Error("AssemblyAI API key is invalid.");
            }
            if (!response.ok) {
                let errorText = await response.text();
                if (errorText) {
                    throw new Error(`AssemblyAI API upload error: ${errorText}`);
                } else {
                    throw new Error(`AssemblyAI API upload error with status: ${response.status}`);
                }
            }
            const data = await response.json();
            return data.upload_url;
        }

        async function getTranscriptionResult(audioUrl) {
            const createTranscriptResponse = await fetch(ASSEMBLYAI_API_URL.replace('/upload', '/transcript'), {
                method: 'POST',
                headers: {
                    'Authorization': ASSEMBLYAI_API_KEY,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ audio_url: audioUrl })
            });
            if (createTranscriptResponse.status === 401) {
                throw new Error("AssemblyAI API key is invalid.");
            }
            if (!createTranscriptResponse.ok) {
                let errorText = await createTranscriptResponse.text();
                if (errorText) {
                    throw new Error(`AssemblyAI API transcript creation error: ${errorText}`);
                } else {
                    throw new Error(`AssemblyAI API transcript creation error with status: ${createTranscriptResponse.status}`);
                }
            }
            const createData = await createTranscriptResponse.json();
            const transcriptId = createData.id;

            let transcriptStatus = 'queued';
            let retries = 0;
            const maxRetries = 10;
            let transcribedText = '';
            
            while (transcriptStatus !== 'completed' && transcriptStatus !== 'error' && retries < maxRetries) {
                await new Promise(resolve => setTimeout(resolve, 2000));
                const checkResponse = await fetch(`${ASSEMBLYAI_API_URL.replace('/upload', '/transcript')}/${transcriptId}`, {
                    method: 'GET',
                    headers: { 'Authorization': ASSEMBLYAI_API_KEY }
                });
                if (checkResponse.status === 401) {
                    throw new Error("AssemblyAI API key is invalid.");
                }
                const checkData = await checkResponse.json();
                transcriptStatus = checkData.status;
                if (transcriptStatus === 'completed') {
                    transcribedText = checkData.text;
                }
                retries++;
            }
            
            if (transcriptStatus !== 'completed') {
                throw new Error(`Transcription failed with status: ${transcriptStatus}`);
            }
            
            return transcribedText;
        }
        
        // --- Gemini Functions ---
        async function generateGeminiText(prompt) {
            const payload = {
                contents: [{
                    parts: [{
                        text: prompt
                    }]
                }],
                generationConfig: {
                    responseModalities: ["TEXT"]
                }
            };

            const response = await fetch(GEMINI_LLM_API_URL, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(payload)
            });

            if (response.status === 403) {
                throw new Error("Gemini LLM API key is invalid.");
            }
            if (!response.ok) {
                let errorText = await response.text();
                if (errorText) {
                    throw new Error(`Gemini LLM API error: ${errorText}`);
                } else {
                    throw new Error(`Gemini LLM API error with status: ${response.status}`);
                }
            }

            const data = await response.json();
            return data.candidates[0].content.parts[0].text;
        }

        async function generateGeminiAudio(text) {
            const payload = {
                contents: [{ parts: [{ text: text }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: 'Despina' }
                        }
                    }
                }
            };

            const response = await fetch(GEMINI_TTS_API_URL, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(payload)
            });

            if (response.status === 403) {
                throw new Error("Gemini TTS API key is invalid.");
            }
            if (!response.ok) {
                let errorText = await response.text();
                if (errorText) {
                    throw new Error(`Gemini TTS API error: ${errorText}`);
                } else {
                    throw new Error(`Gemini TTS API error with status: ${response.status}`);
                }
            }

            const result = await response.json();
            const audioData = result.candidates[0].content.parts[0].inlineData.data;
            const pcmData = base64ToArrayBuffer(audioData);
            const pcm16 = new Int16Array(pcmData);
            const wavBlob = pcmToWav(pcm16, 16000);
            return wavBlob;
        }

        // --- Utility Functions ---
        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        function pcmToWav(pcmData, sampleRate) {
            const numSamples = pcmData.length;
            const buffer = new ArrayBuffer(44 + numSamples * 2);
            const view = new DataView(buffer);

            let offset = 0;
            function writeString(str) {
                for (let i = 0; i < str.length; i++) {
                    view.setUint8(offset++, str.charCodeAt(i));
                }
            }
            function writeUint32(val) {
                view.setUint32(offset, val, true);
                offset += 4;
            }
            function writeUint16(val) {
                view.setUint16(offset, val, true);
                offset += 2;
            }

            writeString('RIFF');
            writeUint32(36 + numSamples * 2);
            writeString('WAVE');
            writeString('fmt ');
            writeUint32(16);
            writeUint16(1); // Audio format (PCM)
            writeUint16(1); // Number of channels
            writeUint32(sampleRate);
            writeUint32(sampleRate * 2); // Byte rate
            writeUint16(2); // Block align
            writeUint16(16); // Bits per sample
            writeString('data');
            writeUint32(numSamples * 2);

            for (let i = 0; i < numSamples; i++) {
                view.setInt16(offset, pcmData[i], true);
                offset += 2;
            }

            return new Blob([view], { type: 'audio/wav' });
        }
    </script>
</body>
</html>
