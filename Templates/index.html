<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Agent - Day 11</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap');
        body {
            font-family: 'Poppins', sans-serif;
            background: linear-gradient(135deg, #fce38a 0%, #fc8a8a 100%);
        }
        .container-card {
            background-color: #ffffff;
            backdrop-filter: blur(10px);
            background-color: rgba(255, 255, 255, 0.9);
            border: 1px solid rgba(255, 255, 255, 0.5);
            box-shadow: 0 10px 25px rgba(0,0,0,0.15);
        }
        .section-card {
            background: rgba(255, 255, 255, 0.7);
            border: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: inset 0 2px 4px rgba(0,0,0,0.05);
        }
        .btn {
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .btn:hover {
            transform: translateY(-2px) scale(1.05);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        .animate-pulse-on-record {
            animation: pulse 1s infinite;
        }
        .message-container {
            display: flex;
            margin-bottom: 1rem;
        }
        .message-container.user {
            justify-content: flex-end;
        }
        .message-container.bot {
            justify-content: flex-start;
        }
        .message-bubble {
            max-width: 75%;
            padding: 0.75rem 1.25rem;
            border-radius: 1.5rem;
            word-wrap: break-word;
            font-size: 1rem;
            line-height: 1.5;
        }
        .message-bubble.user {
            background-color: #d1fae5;
            color: #166534;
            border-bottom-right-radius: 0.5rem;
        }
        .message-bubble.bot {
            background-color: #e0f2fe;
            color: #0c4a6e;
            border-bottom-left-radius: 0.5rem;
        }
    </style>
</head>
<body class="flex items-center justify-center min-h-screen p-4">

    <div class="container-card max-w-4xl w-full mx-auto p-8 rounded-3xl shadow-2xl space-y-8">

        <!-- Header -->
        <header class="text-center">
            <h1 class="text-4xl font-extrabold text-gray-800 flex items-center justify-center">
                <span class="mr-3">30 Days of AI Voice Agents</span> üéôÔ∏è
            </h1>
            <p class="mt-2 text-xl text-gray-600">Day 11: Robust Error Handling</p>
        </header>

        <!-- Chat History Display -->
        <section class="section-card p-6 rounded-2xl border border-gray-200">
            <h2 class="text-2xl font-bold text-gray-700 mb-4">Conversation</h2>
            <div id="chat-history" class="h-64 overflow-y-auto p-4 space-y-4 rounded-xl bg-white shadow-inner">
                <div class="flex justify-center text-sm text-gray-500">
                    <p>Start the conversation below.</p>
                </div>
            </div>
        </section>

        <!-- Voice Agent Control Section -->
        <section class="section-card p-6 rounded-2xl border border-gray-200">
            <h2 class="text-2xl font-bold text-gray-700 mb-4 flex items-center">
                <span class="mr-2">Voice Agent</span> ü§ñ
            </h2>
            <div class="mt-4 space-y-6 text-center">
                <p id="status-message" class="text-gray-600 text-lg transition-all duration-300">Press 'Start Recording' to begin.</p>
                <div class="flex justify-center space-x-6">
                    <button id="startButton" class="btn px-8 py-4 bg-green-500 text-white font-bold rounded-full shadow-lg hover:bg-green-600">
                        üî¥ Start Recording
                    </button>
                    <button id="stopButton" class="btn px-8 py-4 bg-red-500 text-white font-bold rounded-full shadow-lg hover:bg-red-600" disabled>
                        ‚èπÔ∏è Stop Recording
                    </button>
                </div>
                <audio id="audioPlayback" class="w-full mt-6 rounded-lg shadow-inner" controls hidden></audio>
            </div>
        </section>

    </div>

    <script>
        // API Configuration
        // üö® IMPORTANT: Replace these placeholders with your actual API keys.
        const GEMINI_API_KEY = "AIzaSyDbfrWHOC0aNXbG3fAwU_kPYxDW67LxLEw";
        const ASSEMBLYAI_API_KEY = "661f2c6b775c428e8f9647c97314d502";
        const GEMINI_LLM_MODEL = 'gemini-1.5-flash-latest';
        const ASSEMBLYAI_API_URL = 'https://api.assemblyai.com/v2/upload';
        const GEMINI_LLM_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_LLM_MODEL}:generateContent?key=${GEMINI_API_KEY}`;
        
        // DOM Elements
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const audioPlayback = document.getElementById('audioPlayback');
        const statusMessage = document.getElementById('status-message');
        const chatHistoryDiv = document.getElementById('chat-history');

        // State Variables
        let mediaRecorder;
        let audioChunks = [];
        let sessionId;
        let chatHistory = {}; 
        let appState = 'idle';

        // --- Initial Setup and Event Listeners ---
        window.onload = function() {
            if (GEMINI_API_KEY === "INSERT_YOUR_GEMINI_API_KEY_HERE" || ASSEMBLYAI_API_KEY === "INSERT_YOUR_ASSEMBLYAI_API_KEY_HERE") {
                updateStatus('üö® Please set your API keys in the code.', 'text-red-500 font-bold');
                startButton.disabled = true;
            } else {
                setupSessionId();
                startButton.addEventListener('click', startRecording);
                stopButton.addEventListener('click', stopRecording);
                updateUIForState('idle');
            }
        };

        function setupSessionId() {
            const urlParams = new URLSearchParams(window.location.search);
            sessionId = urlParams.get('session_id') || generateUUID();
            if (!urlParams.get('session_id')) {
                window.history.pushState({}, '', `?session_id=${sessionId}`);
            }
            chatHistory[sessionId] = chatHistory[sessionId] || [];
            renderChatHistory();
        }

        // --- UI Utility Functions ---
        function generateUUID() {
            return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
                var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);
                return v.toString(16);
            });
        }
        
        function updateUIForState(state) {
            appState = state;
            switch (appState) {
                case 'idle':
                    updateStatus('Press \'Start Recording\' to begin.');
                    startButton.disabled = false;
                    stopButton.disabled = true;
                    statusMessage.classList.remove('animate-pulse-on-record');
                    break;
                case 'recording':
                    updateStatus('Recording...', 'text-red-500');
                    startButton.disabled = true;
                    stopButton.disabled = false;
                    statusMessage.classList.add('animate-pulse-on-record');
                    break;
                case 'processing':
                    updateStatus('Processing your request...', 'text-blue-500');
                    startButton.disabled = true;
                    stopButton.disabled = true;
                    statusMessage.classList.remove('animate-pulse-on-record');
                    break;
                case 'speaking':
                    updateStatus('Speaking the response...', 'text-green-600');
                    startButton.disabled = true;
                    stopButton.disabled = true;
                    statusMessage.classList.remove('animate-pulse-on-record');
                    break;
            }
        }
        
        function updateStatus(message, color = 'text-gray-600') {
            statusMessage.textContent = message;
            statusMessage.className = `text-lg transition-all duration-300 ${color}`;
        }

        function renderChatHistory() {
            chatHistoryDiv.innerHTML = '';
            if (chatHistory[sessionId].length === 0) {
                chatHistoryDiv.innerHTML = '<div class="flex justify-center text-sm text-gray-500"><p>Start the conversation below.</p></div>';
            } else {
                chatHistory[sessionId].forEach(message => {
                    const messageContainer = document.createElement('div');
                    messageContainer.className = `message-container ${message.role}`;
                    
                    const messageBubble = document.createElement('div');
                    messageBubble.className = `message-bubble ${message.role}`;
                    messageBubble.textContent = message.parts[0].text;
                    
                    messageContainer.appendChild(messageBubble);
                    chatHistoryDiv.appendChild(messageContainer);
                });
                chatHistoryDiv.scrollTop = chatHistoryDiv.scrollHeight;
            }
        }

        // --- Recording Functions ---
        async function startRecording() {
            if (appState !== 'idle') return;
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm; codecs=opus' });
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    handleAudioData();
                };

                mediaRecorder.start();
                updateUIForState('recording');
            } catch (error) {
                console.error('Error accessing microphone:', error);
                updateStatus('Error accessing microphone. Please allow access.', 'text-red-500');
            }
        }

        function stopRecording() {
            if (appState === 'recording') {
                mediaRecorder.stop();
                updateUIForState('processing');
            }
        }

        // --- Main Audio Handling Pipeline with Error Handling ---
        async function handleAudioData() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            let llmResponseText;

            // --- SIMULATE API ERRORS ---
            // Uncomment one of these lines to simulate an error for testing purposes.
            // throw new Error("Simulated STT API failure");
            // throw new Error("Simulated LLM API failure");
            
            try {
                // Step 1: Transcribe using AssemblyAI
                updateStatus('Uploading audio for transcription...', 'text-blue-500');
                const transcriptionUrl = await uploadAudioWithRetry(audioBlob);

                updateStatus('Transcribing audio...', 'text-blue-500');
                const transcribedText = await getTranscriptionWithRetry(transcriptionUrl);
                
                if (!transcribedText) {
                    updateStatus('Transcription was empty. Please try again.', 'text-red-500');
                    updateUIForState('idle'); 
                    return;
                }
                
                chatHistory[sessionId].push({ role: 'user', parts: [{ text: transcribedText }] });
                renderChatHistory();

                // Step 2: Generate response with Gemini LLM using chat history
                updateStatus('Generating response with Gemini...', 'text-blue-500');
                llmResponseText = await generateGeminiText(chatHistory[sessionId]);
                if (!llmResponseText) {
                    updateStatus('Gemini LLM did not return a response.', 'text-red-500');
                    updateUIForState('idle'); 
                    return;
                }
                
                chatHistory[sessionId].push({ role: 'model', parts: [{ text: llmResponseText }] });
                renderChatHistory();
                
                // Step 3: Speak the response using the browser's built-in TTS
                updateStatus('Speaking the response...', 'text-green-600');
                speakResponse(llmResponseText);

            } catch (error) {
                console.error('An error occurred during the voice agent pipeline:', error);
                updateStatus(`Error: ${error.message}`, 'text-red-500');
                // Play a fallback message so the user knows something went wrong.
                speakFallbackResponse();
            }
        }

        function speakResponse(text) {
            const synth = window.speechSynthesis;
            if (synth.speaking) {
                synth.cancel();
            }
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.onend = () => {
                updateUIForState('idle');
            };
            synth.speak(utterance);
            updateUIForState('speaking');
        }

        function speakFallbackResponse() {
            const synth = window.speechSynthesis;
            if (synth.speaking) {
                synth.cancel();
            }
            const utterance = new SpeechSynthesisUtterance("I'm having trouble connecting right now.");
            utterance.onend = () => {
                updateUIForState('idle');
            };
            synth.speak(utterance);
            updateUIForState('speaking');
        }

        // --- API Call Functions with Exponential Backoff Retry ---
        async function fetchWithRetry(url, options, apiName, maxRetries = 5, initialDelay = 1000) {
            for (let i = 0; i < maxRetries; i++) {
                try {
                    const response = await fetch(url, options);
                    if (response.ok) {
                        return response;
                    }
                    if (response.status === 429 || response.status >= 500) {
                        const delay = initialDelay * Math.pow(2, i);
                        updateStatus(`${apiName} API request failed, retrying in ${delay / 1000}s...`);
                        await new Promise(resolve => setTimeout(resolve, delay));
                        continue;
                    }
                    throw new Error(`${apiName} API error: ${response.statusText}`);
                } catch (error) {
                    if (i === maxRetries - 1) throw error;
                    const delay = initialDelay * Math.pow(2, i);
                    updateStatus(`Network error accessing ${apiName}, retrying in ${delay / 1000}s...`);
                    await new Promise(resolve => setTimeout(resolve, delay));
                }
            }
            throw new Error(`${apiName} API request failed after ${maxRetries} retries.`);
        }

        async function uploadAudioWithRetry(audioBlob) {
            const response = await fetchWithRetry(ASSEMBLYAI_API_URL, {
                method: 'POST',
                headers: { 'Authorization': ASSEMBLYAI_API_KEY },
                body: audioBlob
            }, 'AssemblyAI');
            const data = await response.json();
            return data.upload_url;
        }

        async function getTranscriptionWithRetry(audioUrl) {
            const createTranscriptResponse = await fetchWithRetry(ASSEMBLYAI_API_URL.replace('/upload', '/transcript'), {
                method: 'POST',
                headers: { 'Authorization': ASSEMBLYAI_API_KEY, 'Content-Type': 'application/json' },
                body: JSON.stringify({ audio_url: audioUrl })
            }, 'AssemblyAI Transcript Creation');
            const createData = await createTranscriptResponse.json();
            const transcriptId = createData.id;

            let transcriptStatus = 'queued';
            let retries = 0;
            const maxRetries = 20;
            let transcribedText = '';
            
            while (transcriptStatus !== 'completed' && transcriptStatus !== 'error' && retries < maxRetries) {
                await new Promise(resolve => setTimeout(resolve, 2000));
                const checkResponse = await fetch(`${ASSEMBLYAI_API_URL.replace('/upload', '/transcript')}/${transcriptId}`, {
                    method: 'GET',
                    headers: { 'Authorization': ASSEMBLYAI_API_KEY }
                });
                const checkData = await checkResponse.json();
                transcriptStatus = checkData.status;
                if (transcriptStatus === 'completed') { transcribedText = checkData.text; }
                retries++;
            }
            if (transcriptStatus !== 'completed') { 
                throw new Error(`Transcription failed with status: ${transcriptStatus}`); 
            }
            
            return transcribedText;
        }
        
        async function generateGeminiText(history) {
            const payload = {
                contents: history,
                generationConfig: { responseModalities: ["TEXT"] }
            };
            const response = await fetchWithRetry(GEMINI_LLM_API_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            }, 'Gemini LLM');
            const data = await response.json();
            return data.candidates[0].content.parts[0].text;
        }

    </script>
</body>
</html>

