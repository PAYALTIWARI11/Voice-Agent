<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Agent - All-in-One</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap');
        body {
            font-family: 'Poppins', sans-serif;
            /* A more vibrant background gradient */
            background: linear-gradient(135deg, #fce38a 0%, #fc8a8a 100%);
        }
        .container-card {
            background-color: #ffffff;
            backdrop-filter: blur(10px);
            background-color: rgba(255, 255, 255, 0.9);
            border: 1px solid rgba(255, 255, 255, 0.5);
            /* Add a more pronounced shadow for depth */
            box-shadow: 0 10px 25px rgba(0,0,0,0.15);
        }
        .section-card {
            background: rgba(255, 255, 255, 0.7);
            border: 1px solid rgba(255, 255, 255, 0.3);
            box-shadow: inset 0 2px 4px rgba(0,0,0,0.05);
        }
        .btn {
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .btn:hover {
            transform: translateY(-2px) scale(1.05);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        .animate-pulse-on-record {
            animation: pulse 1s infinite;
        }
    </style>
</head>
<body class="flex items-center justify-center min-h-screen p-4">

    <div class="container-card max-w-4xl w-full mx-auto p-8 rounded-3xl shadow-2xl space-y-8">

        <!-- Header for the page -->
        <header class="text-center">
            <h1 class="text-5xl font-extrabold text-gray-800 flex items-center justify-center">
                <span class="mr-3">30 Days of AI Voice Agents</span> üéôÔ∏è
            </h1>
            <p class="mt-2 text-xl text-gray-600">All-in-One: Text-to-Speech & Echo Bot v2</p>
        </header>

        <!-- Text to Speech Section -->
        <section class="section-card p-6 rounded-2xl border border-gray-200">
            <h1 class="text-3xl font-bold text-gray-700 mb-4 flex items-center">
                <span class="mr-2">Text to Speech</span> üó£Ô∏è
            </h1>
            <div class="space-y-4">
                <textarea id="tts-text-area" class="w-full p-4 border border-gray-300 rounded-lg focus:outline-none focus:ring-4 focus:ring-pink-300 transition-colors" rows="4" placeholder="Enter text to convert to speech..."></textarea>
                <div class="flex flex-col sm:flex-row items-center space-y-4 sm:space-y-0 sm:space-x-4">
                    <select id="voice-select" class="w-full sm:w-auto p-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-4 focus:ring-pink-300 transition-colors"></select>
                    <button id="speak-button" class="btn w-full sm:w-auto px-8 py-3 bg-pink-500 text-white font-semibold rounded-lg shadow-lg hover:bg-pink-600">
                        ‚ñ∂Ô∏è Speak
                    </button>
                </div>
            </div>
        </section>

        <!-- Echo Bot Section -->
        <section class="section-card p-6 rounded-2xl border border-gray-200">
            <h1 class="text-3xl font-bold text-gray-700 mb-4 flex items-center">
                <span class="mr-2">Echo Bot</span> ü§ñ
            </h1>
            <div class="mt-4 space-y-6 text-center">
                <p id="status-message" class="text-gray-600 text-lg transition-all duration-300">Press 'Start Recording' to begin.</p>
                <div class="flex justify-center space-x-6">
                    <button id="startButton" class="btn px-8 py-4 bg-green-500 text-white font-bold rounded-full shadow-lg hover:bg-green-600">
                        üî¥ Start Recording
                    </button>
                    <button id="stopButton" class="btn px-8 py-4 bg-red-500 text-white font-bold rounded-full shadow-lg hover:bg-red-600" disabled>
                        ‚èπÔ∏è Stop Recording
                    </button>
                </div>
                <div id="transcription-container" class="mt-6 hidden">
                    <p class="text-xl font-semibold text-gray-800">Transcription:</p>
                    <p id="transcribed-text" class="mt-2 text-gray-600 italic break-words"></p>
                </div>
                <audio id="audioPlayback" class="w-full mt-6 rounded-lg shadow-inner" controls></audio>
            </div>
        </section>

    </div>

    <script>
        // --- Text to Speech Logic ---
        const ttsTextArea = document.getElementById('tts-text-area');
        const voiceSelect = document.getElementById('voice-select');
        const speakButton = document.getElementById('speak-button');
        const synth = window.speechSynthesis;

        let voices = [];

        function populateVoiceList() {
            voices = synth.getVoices().sort((a, b) => a.name.localeCompare(b.name));
            voiceSelect.innerHTML = '';
            voices.forEach(voice => {
                const option = document.createElement('option');
                option.textContent = `${voice.name} (${voice.lang})`;
                option.setAttribute('data-lang', voice.lang);
                option.setAttribute('data-name', voice.name);
                voiceSelect.appendChild(option);
            });
        }

        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = populateVoiceList;
        }
        populateVoiceList();

        speakButton.addEventListener('click', () => {
            const text = ttsTextArea.value;
            if (text !== '') {
                const utterance = new SpeechSynthesisUtterance(text);
                const selectedOption = voiceSelect.selectedOptions[0].getAttribute('data-name');
                utterance.voice = voices.find(voice => voice.name === selectedOption);
                synth.speak(utterance);
            }
        });

        // --- Echo Bot Logic ---
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const audioPlayback = document.getElementById('audioPlayback');
        const statusMessage = document.getElementById('status-message');
        const transcriptionContainer = document.getElementById('transcription-container');
        const transcribedText = document.getElementById('transcribed-text');

        let mediaRecorder;
        let audioChunks = [];

        // Function to start the recording process
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    processAudio(audioBlob);
                };

                mediaRecorder.start();
                startButton.disabled = true;
                stopButton.disabled = false;
                statusMessage.textContent = 'Recording...';
                statusMessage.classList.add('animate-pulse-on-record');
                transcriptionContainer.classList.add('hidden');
                transcribedText.textContent = '';
            } catch (error) {
                console.error('Error accessing microphone:', error);
                statusMessage.textContent = 'Error: Could not access microphone. Please check your permissions.';
                startButton.disabled = false;
                stopButton.disabled = true;
            }
        }

        // Function to stop the recording process
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                startButton.disabled = false;
                stopButton.disabled = true;
                statusMessage.textContent = 'Processing audio... Please wait.';
                statusMessage.classList.remove('animate-pulse-on-record');
            }
        }

        // Function to process the audio Blob and send it to the backend
        async function processAudio(audioBlob) {
            try {
                // Display the "uploaded successfully" message in the UI
                statusMessage.textContent = 'File uploaded successfully. Getting transcription...';

                const formData = new FormData();
                formData.append('audio_file', audioBlob, 'audio.webm');

                const response = await fetch('/tts/echo', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'An unknown error occurred.');
                }
                
                const responseData = await response.json();
                const transcription = responseData.transcription;
                const audioBase64 = responseData.audio;

                if (transcription) {
                    statusMessage.textContent = 'Transcription and audio received! Playing back...';
                    transcribedText.textContent = transcription;
                    transcriptionContainer.classList.remove('hidden');

                    // Convert Base64 audio to a Blob and play it
                    const audioBlob = b64toBlob(audioBase64, 'audio/wav');
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPlayback.src = audioUrl;
                    audioPlayback.play();
                } else {
                    throw new Error('Transcription was empty.');
                }

            } catch (error) {
                console.error('Error:', error);
                statusMessage.textContent = `Error: ${error.message}`;
            }
        }

        // Helper function to convert a Base64 string to a Blob
        function b64toBlob(b64Data, contentType = '', sliceSize = 512) {
            const byteCharacters = atob(b64Data);
            const byteArrays = [];
            for (let offset = 0; offset < byteCharacters.length; offset += sliceSize) {
                const slice = byteCharacters.slice(offset, offset + sliceSize);
                const byteNumbers = new Array(slice.length);
                for (let i = 0; i < slice.length; i++) {
                    byteNumbers[i] = slice.charCodeAt(i);
                }
                const byteArray = new Uint8Array(byteNumbers);
                byteArrays.push(byteArray);
            }
            return new Blob(byteArrays, { type: contentType });
        }


        // Add event listeners to the buttons
        startButton.addEventListener('click', startRecording);
        stopButton.addEventListener('click', stopRecording);
    </script>
</body>
</html>
