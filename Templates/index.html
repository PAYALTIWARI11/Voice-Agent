<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Agent - Day 6</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700;800&display=swap');
        body {
            font-family: 'Poppins', sans-serif;
            /* Vibrant, deep gradient background */
            background: linear-gradient(135deg, #6a11cb 0%, #2575fc 100%);
            color: #e2e8f0; /* Light text for contrast */
            min-height: 100vh; /* Ensure body takes full viewport height */
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start; /* Align content to the top */
            padding: 2rem; /* Add some padding around the content */
        }
        .container-card {
            background-color: rgba(30, 30, 45, 0.9); /* Darker, slightly transparent background */
            border: 1px solid rgba(70, 70, 90, 0.5);
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4); /* Stronger shadow */
            z-index: 10; /* Ensure it's above any background elements */
            position: relative;
            margin-bottom: 2rem; /* Space between cards */
        }
        .section-card {
            background: rgba(45, 45, 65, 0.7); /* Darker section background */
            border: 1px solid rgba(80, 80, 100, 0.5);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3); /* Section shadow */
            transition: all 0.3s ease-in-out;
            position: relative;
            overflow: hidden;
            margin-bottom: 2rem; /* Space between sections when stacked */
        }
        .section-card:last-child {
            margin-bottom: 0; /* No margin after the last section */
        }
        .section-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.4);
        }
        .btn {
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
            z-index: 1;
            cursor: pointer; /* Ensure cursor changes on hover */
            display: inline-flex; /* Use flex to ensure content is centered and visible */
            align-items: center;
            justify-content: center;
        }
        .btn::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 300%;
            height: 300%;
            background: rgba(255, 255, 255, 0.15);
            border-radius: 50%;
            transition: all 0.5s ease-out;
            transform: translate(-50%, -50%) scale(0);
            z-index: -1;
        }
        .btn:hover::before {
            transform: translate(-50%, -50%) scale(1);
        }

        /* Specific button colors and glows */
        #speak-button {
            background-color: #8B5CF6; /* Purple */
            box-shadow: 0 5px 15px rgba(139, 92, 246, 0.4);
        }
        #speak-button:hover {
            background-color: #7C3AED; /* Darker purple */
            box-shadow: 0 0 20px rgba(139, 92, 246, 0.8); /* Glow */
        }
        #startButton {
            background-color: #10B981; /* Green */
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }
        #startButton:hover {
            background-color: #059669; /* Darker green */
            box_shadow: 0 0 20px rgba(16, 185, 129, 0.8); /* Glow */
        }
        #stopButton {
            background-color: #EF4444; /* Red */
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }
        #stopButton:hover {
            background-color: #DC2626; /* Darker red */
            box_shadow: 0 0 20px rgba(239, 68, 68, 0.8); /* Glow */
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.02); opacity: 0.8; }
        }
        .animate-pulse-on-record {
            animation: pulse 1s infinite alternate;
            color: #60a5fa; /* Blue for recording status */
        }
        .status-success {
            color: #34d399; /* Green for success */
        }
        .status-error {
            color: #f87171; /* Red for error */
        }
    </style>
</head>
<body class="flex flex-col items-center min-h-screen p-4">

    <div class="container-card max-w-4xl w-full mx-auto p-8 rounded-3xl space-y-8 mb-8">

        <!-- Header for the page -->
        <header class="text-center mb-8">
            <h1 class="text-6xl font-extrabold text-white leading-tight">30 Days of AI Voice Agents üöÄ</h1>
            <p class="mt-3 text-2xl text-gray-300">Day 6: Voice-to-Text Transcription üó£Ô∏è</p>
        </header>

        <!-- Text to Speech Section -->
        <section class="section-card p-8 rounded-2xl">
            <h1 class="text-4xl font-bold text-white mb-6">Text to Speech ‚ú®</h1>
            <div class="space-y-6">
                <textarea id="tts-text-area" class="w-full p-4 border border-gray-600 rounded-lg bg-gray-800 text-white placeholder-gray-500 focus:outline-none focus:ring-4 focus:ring-blue-600 transition-colors duration-200" rows="5" placeholder="Enter text to convert to speech..."></textarea>
                <div class="flex flex-col sm:flex-row items-center space-y-4 sm:space-y-0 sm:space-x-4">
                    <select id="voice-select" class="w-full sm:w-auto p-3 border border-gray-600 rounded-lg bg-gray-800 text-white focus:outline-none focus:ring-4 focus:ring-blue-600 transition-colors duration-200"></select>
                    <button id="speak-button" class="btn w-full sm:w-auto px-10 py-4 bg-purple-600 text-white font-bold rounded-xl shadow-lg hover:bg-purple-700">Speak</button>
                </div>
            </div>
        </section>

        <!-- Voice-to-Text Section -->
        <section class="section-card p-8 rounded-2xl">
            <h1 class="text-4xl font-bold text-white mb-6">Echo Bot with Transcription üé§</h1>
            <div class="mt-4 space-y-8 text-center">
                <p id="echo-status-message" class="text-gray-300 text-xl transition-all duration-300">Click 'Start Recording' to begin your voice recording for transcription! üîä</p>
                <div class="flex justify-center space-x-8">
                    <button id="startButton" class="btn px-10 py-5 bg-green-500 text-white font-bold rounded-full shadow-lg hover:bg-green-600">Start Recording</button>
                    <button id="stopButton" class="btn px-10 py-5 bg-red-500 text-white font-bold rounded-full shadow-lg hover:bg-red-600" disabled>Stop Recording</button>
                </div>
                <div class="mt-8 text-left">
                    <h2 class="text-2xl font-bold text-white mb-2">Transcription:</h2>
                    <p id="transcript-display" class="p-4 border border-gray-600 rounded-lg bg-gray-800 text-white text-lg min-h-[5rem] overflow-auto">The transcribed text will appear here...</p>
                </div>
            </div>
        </section>

    </div>

    <script>
        // --- Text to Speech Logic ---
        const textArea = document.getElementById('tts-text-area');
        const voiceSelect = document.getElementById('voice-select');
        const speakButton = document.getElementById('speak-button');
        const synth = window.speechSynthesis;

        let voices = [];

        function populateVoiceList() {
            voices = synth.getVoices().sort((a, b) => a.name.localeCompare(b.name));
            voiceSelect.innerHTML = '';
            if (voices.length === 0) {
                console.warn('TTS: No voices found. Make sure your browser supports SpeechSynthesis and has voices installed.');
                const option = document.createElement('option');
                option.textContent = 'No voices available';
                voiceSelect.appendChild(option);
                speakButton.disabled = true;
                return;
            }
            voices.forEach(voice => {
                const option = document.createElement('option');
                option.textContent = `${voice.name} (${voice.lang})`;
                option.setAttribute('data-lang', voice.lang);
                option.setAttribute('data-name', voice.name);
                voiceSelect.appendChild(option);
            });
            console.log('TTS: Voices populated. Found', voices.length, 'voices.');
            speakButton.disabled = false; // Enable speak button once voices are loaded
        }

        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = populateVoiceList;
        }
        populateVoiceList(); // Call immediately in case voices are already loaded

        speakButton.addEventListener('click', () => {
            const text = textArea.value;
            console.log('TTS: Speak button clicked. Text:', text);
            if (text.trim() !== '') {
                const utterance = new SpeechSynthesisUtterance(text);
                const selectedOption = voiceSelect.selectedOptions[0];
                if (selectedOption) {
                    const selectedVoiceName = selectedOption.getAttribute('data-name');
                    utterance.voice = voices.find(voice => voice.name === selectedVoiceName);
                } else {
                    console.warn('TTS: No voice selected or available.');
                }
                synth.speak(utterance);
            } else {
                console.warn('TTS: No text entered for speech.');
            }
        });

        // --- Echo Bot with Transcription Logic (Day 6 Updates) ---
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const echoStatusMessage = document.getElementById('echo-status-message');
        const transcriptDisplay = document.getElementById('transcript-display');

        let mediaRecorder;
        let audioChunks = [];

        async function startRecording() {
            console.log('Transcription Bot: Attempting to start recording...');
            echoStatusMessage.textContent = 'Requesting microphone access... Please allow the browser pop-up.';
            transcriptDisplay.textContent = 'The transcribed text will appear here...'; // Reset transcription display

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log('Transcription Bot: Microphone access granted.');

                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                    console.log('Transcription Bot: Data available, chunk size:', event.data.size);
                };

                mediaRecorder.onstop = async () => {
                    console.log('Transcription Bot: Recording stopped. Total chunks:', audioChunks.length);
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    echoStatusMessage.textContent = 'Recording finished. Sending to server for transcription...';
                    echoStatusMessage.classList.remove('animate-pulse-on-record');
                    transcriptDisplay.textContent = 'Transcribing audio... Please wait.';

                    const formData = new FormData();
                    const filename = `recorded_audio_${Date.now()}.webm`;
                    formData.append('audio_file', audioBlob, filename);

                    try {
                        console.log('Transcription Bot: Attempting to transcribe audio via server...');
                        const response = await fetch('http://127.0.0.1:8000/transcribe/file', {
                            method: 'POST',
                            body: formData,
                        });

                        if (!response.ok) {
                            const errorText = await response.text();
                            console.error('Transcription Bot: Server transcription failed:', response.status, errorText);
                            throw new Error(`HTTP error! Status: ${response.status}. Details: ${errorText}`);
                        }

                        const result = await response.json();
                        if (result.transcription) {
                            echoStatusMessage.textContent = `Transcription successful!`;
                            echoStatusMessage.classList.add('status-success');
                            transcriptDisplay.textContent = result.transcription;
                            console.log('Transcription Bot: Transcription received:', result.transcription);
                        } else {
                            echoStatusMessage.textContent = `Transcription failed: No text returned.`;
                            echoStatusMessage.classList.add('status-error');
                            transcriptDisplay.textContent = 'Transcription failed.';
                        }

                    } catch (transcribeError) {
                        console.error('Transcription Bot: Transcription failed:', transcribeError);
                        if (transcribeError.message.includes("Failed to fetch")) {
                            echoStatusMessage.textContent = `Transcription failed: Could not connect to server. Is your FastAPI backend running?`;
                        } else {
                            echoStatusMessage.textContent = `Transcription failed: ${transcribeError.message}.`;
                        }
                        echoStatusMessage.classList.add('status-error');
                        transcriptDisplay.textContent = 'Transcription failed.';
                    } finally {
                        startButton.disabled = false;
                        stopButton.disabled = true;
                    }
                };

                mediaRecorder.start();
                startButton.disabled = true;
                stopButton.disabled = false;
                echoStatusMessage.textContent = 'Recording... Speak clearly now!';
                echoStatusMessage.classList.add('animate-pulse-on-record');
            } catch (error) {
                console.error('Transcription Bot: Error accessing microphone:', error);
                echoStatusMessage.textContent = 'Error: Microphone access denied or not found. Please enable it.';
                echoStatusMessage.classList.add('status-error');
                echoStatusMessage.classList.remove('animate-pulse-on-record');
                startButton.disabled = false;
                stopButton.disabled = true;
            }
        }

        function stopRecording() {
            console.log('Transcription Bot: Attempting to stop recording...');
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                console.log('Transcription Bot: Recording stopped and microphone tracks released.');
            }
        }

        startButton.addEventListener('click', startRecording);
        stopButton.addEventListener('click', stopRecording);
    </script>
</body>
</html>
